{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0dc7f9-9454-46b1-84b5-d22c1d3b97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library\n",
    "# These codes can be used for crawling the recent articles published in Chinese Journals\n",
    "# tigerwp@njnu.edu.cn\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "import urllib\n",
    "from urllib.parse import urljoin\n",
    "# bs4 for static web page\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ed1447-0ac6-408c-bc0d-dc94bbd80fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using selenium for dynamic web page\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--lang=zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8d4bac-f586-40ef-b1fd-8caec607a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Keywords for searching\n",
    "keywords=['热年代','裂变径迹','剥蚀','剥露','热演化','热机制','构造隆升','剪切带','变质','Ar']\n",
    "#keywords=['碎屑锆石','沉积环境','走滑','古地理','演化','盆地']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a032b-d707-4013-b2f4-59c112566d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Send a GET request to the API and store the response\n",
    "\n",
    "print('# 01 ---- 《地学前缘》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.earthsciencefrontiers.net.cn/CN/1005-2321/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.find('title').text)\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            #<p></p> for abstract and <a></a> for article title\n",
    "            if tag.p != None:\n",
    "                if keywords[i] in tag.a.text: # or keywords[i] in tag.p.text: \n",
    "                    tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地学前缘')\n",
    "print('# 02 ---- 《现代地质》 --------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.geoscience.net.cn/CN/1000-8527/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.find('title').text)\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            #<p></p> for abstract and <a></a> for article title\n",
    "            if tag.p != None:\n",
    "                if keywords[i] in tag.a.text: # or keywords[i] in tag.p.text: \n",
    "                    tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 现代地质')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f007a-a8c9-4035-a1f3-abc2cddfb09f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('# 03 ---- 《地球物理学报》 ------------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"http://www.geophy.cn/\")\n",
    "#using class name to select the tags (title and abstract) for searching\n",
    "tags = driver.find_elements(By.CLASS_NAME, \"article-list-title > a\")\n",
    "for tag in tags:\n",
    "    tag_ok=False\n",
    "    for i in range(len(keywords)):\n",
    "        if keywords[i] in tag.text:\n",
    "            tag_ok=True\n",
    "    if tag_ok:    \n",
    "        print(tag.text)\n",
    "        link = tag.get_attribute(\"href\")\n",
    "        print(link)\n",
    "        print('=============================================================================')\n",
    "driver.quit()\n",
    "print('# 04 ---- 《地质科学》 -------------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"http://www.dzkx.org/CN/volumn/current.shtml\")\n",
    "#print(driver.title)\n",
    "#using class name to select the tags (title and abstract) for searching\n",
    "tags = driver.find_elements(By.CLASS_NAME, \"article-list-title > a\")\n",
    "for tag in tags:\n",
    "    tag_ok=False\n",
    "    for i in range(len(keywords)):\n",
    "        if keywords[i] in tag.text:\n",
    "            tag_ok=True\n",
    "    if tag_ok:\n",
    "        print(tag.text)\n",
    "        link = tag.get_attribute(\"href\")\n",
    "        print(link)\n",
    "        print('=============================================================================')\n",
    "driver.quit()\n",
    "print('# 05 ---- 《岩石学报》 -------------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"http://www.ysxb.ac.cn/\")\n",
    "#print(driver.title)\n",
    "#using class name to select the tags (title and abstract) for searching\n",
    "tags = driver.find_elements(By.CLASS_NAME, \"article-list-title > a\")\n",
    "for tag in tags:\n",
    "    tag_ok=False\n",
    "    for i in range(len(keywords)):\n",
    "        if keywords[i] in tag.text:\n",
    "            tag_ok=True\n",
    "    if tag_ok:\n",
    "        print(tag.text)\n",
    "        link = tag.get_attribute(\"href\")\n",
    "        print(link)\n",
    "        print('=============================================================================')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037a2874-f085-4a9b-b3c6-9bc6a017fe7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 06 ---- 《第四纪研究》 -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('# 06 ---- 《第四纪研究》 -------------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"http://www.dsjyj.com.cn/\")\n",
    "#print(driver.title)\n",
    "#using class name to select the tags (title and abstract) for searching\n",
    "tags = driver.find_elements(By.CLASS_NAME, \"article-list-title > a\")\n",
    "for tag in tags:\n",
    "    tag_ok=False\n",
    "    for i in range(len(keywords)):\n",
    "        if keywords[i] in tag.text:\n",
    "            tag_ok=True\n",
    "    if tag_ok:\n",
    "        print(tag.text)\n",
    "        link = tag.get_attribute(\"href\")\n",
    "        print(link)\n",
    "        print('=============================================================================')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b4ab52-c798-40ea-a09f-082434c8f248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 07 ---- 《地质学报》 -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigerwp\\.conda\\envs\\database\\Lib\\site-packages\\urllib3\\connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.geojournals.cn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "柴达木盆地北缘鱼卡超高压变质地体中花岗质岩石的成因与多期地壳再造事件\n",
      "https://www.geojournals.cn/dzxb/dzxb/article/abstract/2024264\n",
      "============================================================================\n",
      "付雪梅等： 柴达木盆地北缘鱼卡超高压变质地体中花岗质岩石的成因与多期地壳再造事件——附件\n",
      "https://www.geojournals.cn/dzxb/dzxb/article/abstract/202508092\n",
      "============================================================================\n",
      "准噶尔盆地周缘造山带裂变径迹研究及其地质意义\n",
      "https://www.geojournals.cn/dzxb/dzxb/article/abstract/20090058\n",
      "============================================================================\n",
      "# 08 ---- 《地质论评》 -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('# 07 ---- 《地质学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "url = \"https://www.geojournals.cn/dzxb/\"\n",
    "response = requests.get(\"https://www.geojournals.cn/dzxb/dzxb/home\",verify=False)\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tags in soup.find_all('div',class_=\"des m-fl\"):\n",
    "        tag = tags.find('div',class_=\"title\")\n",
    "        tag_ok=False\n",
    "        if tag.a != None:\n",
    "            title = tag.a.text\n",
    "            abstract = tags.select('.intro > p')[1].get_text(strip=True)\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in title: # or keywords[i] in abstract: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(title)\n",
    "                print(urljoin(url,tags.a['href']))\n",
    "                print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地质学报')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083bd664-7909-4d05-ade1-ddad40567020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 08 ---- 《地质论评》 -------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigerwp\\.conda\\envs\\database\\Lib\\site-packages\\urllib3\\connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.geojournals.cn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "滇西北金沙江缝合带格亚顶—茂顶地区变质岩系的\n",
      "锆石LA MC ICP MS U Pb年龄\n",
      "——原岩的沉积时代和物源区特征\n",
      "https://www.geojournals.cn/georev/georev/article/abstract/20135906012\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "print('# 08 ---- 《地质论评》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "url = \"https://www.geojournals.cn/georev/\"\n",
    "response = requests.get(\"https://www.geojournals.cn/georev/georev/home\",verify=False)\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tags in soup.find_all('div',class_=\"des m-fl\"):\n",
    "        tag = tags.find('div',class_=\"title\")\n",
    "        tag_ok=False\n",
    "        if tag.a != None:\n",
    "            title = tag.a.text\n",
    "            abstract = tags.select('.intro > p')[1].get_text(strip=True)\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in title: #or keywords[i] in abstract: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(title)\n",
    "                print(urljoin(url,tags.a['href']))\n",
    "                print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地质论评')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f976f-7c2c-44ff-b7b0-ac1d49796dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('# 09 ---- 《岩石矿物学杂志》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.yskw.ac.cn/yskwxzz/home\")\n",
    "url = \"https://www.yskw.ac.cn/yskwxzz\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tags in soup.find_all('div',class_=\"des m-fl\"):\n",
    "        tag = tags.find('div',class_=\"title\")\n",
    "        tag_ok=False\n",
    "        if tag.a != None:\n",
    "            title = tag.a.text\n",
    "            abstract = tags.select('.intro > p')[1].get_text(strip=True)\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in title: #or keywords[i] in abstract: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(title)\n",
    "                print(urljoin(url,tags.a['href']))\n",
    "                print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 岩石矿物学杂志')\n",
    "print('# 10 ---- 《大地构造和成矿学》 -------------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.set_page_load_timeout(50)\n",
    "try:\n",
    "    driver.get(\"http://www.ddgzyckx.com/#/\")\n",
    "    url = \"http://www.ddgzyckx.com/#/digest?ArticleID=\"\n",
    "    #print(driver.title)\n",
    "    #using class name to select the tags (title and abstract) for searching\n",
    "    tags = driver.find_elements(By.CLASS_NAME, \"tab_con_left\")\n",
    "    for tag in tags:\n",
    "        parent_class=tag.find_element(By.XPATH, \"..\").get_attribute(\"class\")\n",
    "        num = parent_class.lstrip('tab_con')\n",
    "        title = tag.find_element(By.CLASS_NAME, \"ml_title > a\")\n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in title.text:\n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(title.text)\n",
    "            link = url+num\n",
    "            print(link)\n",
    "            print('=============================================================================')\n",
    "except TimeoutException:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "driver.quit()\n",
    "print('# 11 ---- 《地球化学》 -------------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.set_page_load_timeout(50)\n",
    "try:\n",
    "    driver.get(\"http://www.geochimica.cn/#/\")\n",
    "    url = \"http://www.geochimica.cn/#/digest?ArticleID=\"\n",
    "    #print(driver.title)\n",
    "    #using class name to select the tags (title and abstract) for searching\n",
    "    tags = driver.find_elements(By.CLASS_NAME, \"tab_con_left\")\n",
    "    for tag in tags:\n",
    "        parent_class=tag.find_element(By.XPATH, \"..\").get_attribute(\"class\")\n",
    "        num = parent_class.lstrip('tab_con')\n",
    "        title = tag.find_element(By.CLASS_NAME, \"ml_title > a\")\n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in title.text:\n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(title.text)\n",
    "            link = url+num\n",
    "            print(link)\n",
    "            print('=============================================================================')\n",
    "except TimeoutException:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a06509a-c477-4016-a9c1-be1d1df0c5df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 12 ---- 《地球科学》 -------------------------------------\n",
      "基于低温热年代学约束下的秦岭北麓构造抬升过程研究进展\n",
      "http://www.earth-science.net/cn/article/doi/10.3799/dqkx.2025.070\n",
      "============================================================================\n",
      "藏东玉龙斑岩铜矿剥蚀历史与保存程度—热年代学约束\n",
      "http://www.earth-science.net/cn/article/doi/10.3799/dqkx.2024.151\n",
      "============================================================================\n",
      "泥页岩中有机质：类型、热演化与有机孔隙\n",
      "http://www.earth-science.net/cn/article/id/34d609c6-fc43-42fb-8b6a-2d855506ef67\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "print('# 12 ---- 《地球科学》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://www.earth-science.net/index.htm\")\n",
    "url =\"http://www.earth-science.net\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.find('title').text)\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tag in soup.find_all('div',class_=\"article-list\"): \n",
    "        abstract = tag.find('span', class_=\"require_sub\") \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            #if abstract.text != None:\n",
    "            if keywords[i] in tag.a.text: # or keywords[i] in abstract.text\n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地球科学')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08ae0fa-cd31-4b08-bc4f-cdb12e856338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 13 ---- 《吉林大学学报（地球科学版）》 --------------------------------\n",
      "\n",
      "华北克拉通中部造山带河北良岗榴闪岩变质作用演化及其地质意义\n",
      "\n",
      "http://xuebao.jlu.edu.cn/dxb/CN/10.13278/j.cnki.jjuese.20230326\n",
      "============================================================================\n",
      "# 14 ---- 《高校地质学报》 -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('# 13 ---- 《吉林大学学报（地球科学版）》 --------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://xuebao.jlu.edu.cn/dxb/CN/1671-5888/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.find('title').text)\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "        abstract = tag.find('div', class_=\"white_content\") \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "#            if abstract.text != None:\n",
    "            if keywords[i] in tag.a.text: #or keywords[i] in abstract.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 吉林大学学报（地球科学版）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cb918bb-6270-4f1c-b74c-2a02c804de41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 14 ---- 《高校地质学报》 -------------------------------------\n",
      "# 15 ---- 《地质力学学报》 -------------------------------------\n",
      "浙东南火山岩区磷灰石裂变径迹研究及地质意义\n",
      "https://journal.geomech.ac.cn/cn/article/doi/10.12090/j.issn.1006-6616.2025016\n",
      "============================================================================\n",
      "北山造山带韧性剪切带的分布、特征、时代与环境\n",
      "https://journal.geomech.ac.cn/cn/article/doi/10.12090/j.issn.1006-6616.2025027\n",
      "============================================================================\n",
      "# 16 ---- 《矿物岩石地球化学通报》 ---------------------------------\n",
      "# 17 ---- 《中国科学:地球科学》 ---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('# 14 ---- 《高校地质学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://geology.nju.edu.cn/CN/1006-7493/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.find('title').text)\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "        abstract = tag.find('div', class_=\"white_content zhaiyao\") \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "#            if abstract.text != None:\n",
    "            if keywords[i] in tag.a.text: #or keywords[i] in abstract.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 高校地质学报')\n",
    "print('# 15 ---- 《地质力学学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://journal.geomech.ac.cn/index.htm\")\n",
    "url =\"https://journal.geomech.ac.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地质力学学报')\n",
    "print('# 16 ---- 《矿物岩石地球化学通报》 ---------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.set_page_load_timeout(50)\n",
    "try:\n",
    "    driver.get(\"https://www.sciengine.com/BMPG/issue\")\n",
    "    # because the webpage is en in default and can only be changed to zh-CN by click \n",
    "    driver.find_element(By.CSS_SELECTOR, '.language').click()\n",
    "    time.sleep(5)\n",
    "    #using class name to select the tags (title and abstract) for searching\n",
    "    tags = driver.find_elements(By.CLASS_NAME, \"title > a\")\n",
    "    for tag in tags:\n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.text:\n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.text)\n",
    "            link = tag.get_attribute(\"href\")\n",
    "            print(link)\n",
    "            print('=============================================================================')\n",
    "except TimeoutException:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "driver.quit()\n",
    "print('# 17 ---- 《中国科学:地球科学》 ---------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.set_page_load_timeout(50)\n",
    "try:\n",
    "    driver.get(\"https://www.sciengine.com/SSTe/issue\")\n",
    "    #using class name to select the tags (title and abstract) for searching\n",
    "    tags = driver.find_elements(By.CLASS_NAME, \"title > a\")\n",
    "    for tag in tags:\n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.text:\n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.text)\n",
    "            link = tag.get_attribute(\"href\")\n",
    "            print(link)\n",
    "            print('=============================================================================')\n",
    "except TimeoutException:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8d4778-357a-4eea-a84f-0dc48d25e005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 18 ---- 《中国地质》 -------------------------------------\n",
      "龙门山冲断带中—新生代隆升及扩展的热年代学证据\n",
      "http://geochina.cgs.gov.cn/article/doi/10.12029/gc20220306001\n",
      "============================================================================\n",
      "甘肃北山南带石炭系中新发现韧性剪切带型金矿床（6吨）\n",
      "http://geochina.cgs.gov.cn/article/doi/10.12029/gc\n",
      "============================================================================\n",
      "松辽外围南部秀水盆地构造-热演化史的磷灰石裂变径迹分析\n",
      "http://geochina.cgs.gov.cn/article/doi/10.12029/gc20240204-9\n",
      "============================================================================\n",
      "松辽外围南部秀水盆地构造−热演化史的磷灰石裂变径迹分析\n",
      "http://geochina.cgs.gov.cn/article/doi/10.12029/gc20210407001\n",
      "============================================================================\n",
      "琼北变质基底片麻岩的锆石U−Pb年龄\n",
      "http://geochina.cgs.gov.cn/article/doi/10.12029/gc20240513001\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "print('# 18 ---- 《中国地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://geochina.cgs.gov.cn/\")\n",
    "url =\"http://geochina.cgs.gov.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 中国地质')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312a689-d274-4a15-aef7-b5afe0a4bfae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('# 19 ---- 《地球学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://www.cagsbulletin.com/dqxbcn/ch/index.aspx\")\n",
    "url =\"http://www.cagsbulletin.com/dqxbcn/ch/\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.find('title').text)\n",
    "    # using class to select the tags (title and abstract) for searching\n",
    "    tags_doc= soup.find('div',class_='mulu-k')\n",
    "    soup_tags=BeautifulSoup('<html>'+str(tags_doc)+'</html>','html.parser')\n",
    "    for tag in soup_tags.find_all('li'):\n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: # or keywords[i] in abstract.text\n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text)\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地球学报')\n",
    "print('# 20 ---- 《地质通报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://dzhtb.cgs.cn/\")\n",
    "url =\"http://dzhtb.cgs.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地质通报')\n",
    "print('# 21 ---- 《岩矿测试》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://www.ykcs.ac.cn/\")\n",
    "url =\"http://www.ykcs.ac.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 岩矿测试')\n",
    "print('# 22 ---- 《石油学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.syxb-cps.com.cn/CN/0253-2697/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('li',class_=\"biaoti\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 石油学报')\n",
    "print('# 23 ---- 《地球科学进展》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://www.adearth.ac.cn/CN/1001-8166/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"col-md-9\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地球科学进展')\n",
    "print('# 24 ---- 《海洋地质与第四纪地质》 -------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"http://jhydz.com.cn/\")\n",
    "#using class name to select the tags (title and abstract) for searching\n",
    "tags = driver.find_elements(By.CLASS_NAME, \"article-list-title > a\")\n",
    "for tag in tags:\n",
    "    tag_ok=False\n",
    "    for i in range(len(keywords)):\n",
    "        if keywords[i] in tag.text:\n",
    "            tag_ok=True\n",
    "    if tag_ok:\n",
    "        print(tag.text)\n",
    "        link = tag.get_attribute(\"href\")\n",
    "        print(link)\n",
    "        print('=============================================================================')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2f95aed-fc8e-453f-b7d9-d0f35f8a6d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 25 ---- 《地质科技通报》 -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('# 25 ---- 《地质科技通报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://dzkjtb.cug.edu.cn/\")\n",
    "url=\"https://dzkjqb.cug.edu.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地质科技通报')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e5889-5fac-4702-894a-dfb13d7e8db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('# 26 ---- 《古地理学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "try:\n",
    "    response = requests.get(\"http://www.gdlxb.cn/CN/volumn/current.shtml\", timeout=(3, 5))\n",
    "    url=\"http://www.gdlxb.cn/CN\"\n",
    "    # Check if the request was successful (status code 200 indicates success)\n",
    "    # def has_b(tag):\n",
    "    #     return tag.b is not None\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        for tag in soup.find_all('td', colspan=\"2\", height=\"22\", valign=\"center\"): \n",
    "            tag_ok=False\n",
    "            if tag.b !=None:\n",
    "                for i in range(len(keywords)):\n",
    "                    if keywords[i] in tag.b.text: \n",
    "                        tag_ok=True\n",
    "                if tag_ok:\n",
    "                    print(tag.b.text.rstrip('*'))\n",
    "                    address=tag.find_next('td', colspan=\"2\", height=\"22\", valign=\"center\")\n",
    "                    print(url+address.a['href'].lstrip('.'))\n",
    "                    print('============================================================================')\n",
    "    else: \n",
    "        print('can not connet to 古地理学报')\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "print('# 27 ---- 《沉积学报》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "try:\n",
    "    response = requests.get(\"http://www.cjxb.ac.cn/\", timeout=(3, 5))\n",
    "    url=\"http://www.cjxb.ac.cn\"\n",
    "    # Check if the request was successful (status code 200 indicates success)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        #print(soup.find('title').text)\n",
    "        # using class to select the tags (title and abstract) for searching\n",
    "        for tag in soup.find_all('div',class_=\"article-list\"): \n",
    "            title = tag.find('div', class_=\"article-list-title\") \n",
    "            abstract = tag.find('div',class_=\"article-list-zy morenstyle\")\n",
    "            tag_ok=False\n",
    "            for i in range(len(keywords)):\n",
    "    #            if abstract.text != None:\n",
    "                if keywords[i] in title.a.text: #or keywords[i] in abstract.text: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(title.a.text)\n",
    "                print(url+title.a['href']) # get the link for the article\n",
    "                print('============================================================================')\n",
    "    else: \n",
    "        print('can not connet to 沉积学报')\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "    \n",
    "print('# 28 ---- 《沉积与特提斯地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "try:\n",
    "    response = requests.get(\"https://www.cjyttsdz.com.cn/\", timeout=(3, 5))\n",
    "    url=\"https://www.cjyttsdz.com.cn\"\n",
    "    # Check if the request was successful (status code 200 indicates success)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "            tag_ok=False\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in tag.a.text: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(tag.a.text.strip())\n",
    "                print(url+tag.a['href']) # get the link for the article\n",
    "                print('============================================================================')\n",
    "    else: \n",
    "        print('can not connet to 沉积与特提斯地质')\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "    \n",
    "print('# 29 ---- 《地震地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "try:\n",
    "    response = requests.get(\"https://www.dzdz.ac.cn/CN/0253-4967/home.shtml\", timeout=(3, 5))\n",
    "    # Check if the request was successful (status code 200 indicates success)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        #print(soup.find('title').text)\n",
    "        # using class to select the tags (title and abstract) for searching\n",
    "        for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "            tag_ok=False\n",
    "            for i in range(len(keywords)):\n",
    "    #            if abstract.text != None:\n",
    "                if keywords[i] in tag.a.text: #or keywords[i] in abstract.text: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(tag.a.text)\n",
    "                print(tag.a['href']) # get the link for the article\n",
    "                print('============================================================================')\n",
    "    else: \n",
    "        print('can not connet to 地震地质')\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"连接超时！换个时间再试试！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddf4570f-b164-4760-bbfc-521176f903c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 30 ---- 《西北地质》 -------------------------------------\n",
      "鄂尔多斯盆地构造热演化对富氦天然气富集的控制作用初探\n",
      "https://xbdz.net.cn/article/doi/10.12401/j.nwg.2025004\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "print('# 30 ---- 《西北地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "try:\n",
    "    response = requests.get(\"https://xbdz.net.cn/\",timeout=(3, 5))\n",
    "    url =\"https://xbdz.net.cn\"\n",
    "    # Check if the request was successful (status code 200 indicates success)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "            tag_ok=False\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in tag.a.text: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(tag.a.text.strip())\n",
    "                print(url+tag.a['href']) # get the link for the article\n",
    "                print('============================================================================')\n",
    "    else: \n",
    "        print('can not connet to 西北地质')\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"连接超时！换个时间再试试！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0d25759-1d98-4cb4-b913-0e9d9447b4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 31 ---- 《石油实验地质》 -------------------------------------\n",
      "# 32 ---- 《地球科学与环境学报》 ----------------------------------\n",
      "# 33 ---- 《华东地质》 -------------------------------------\n",
      "低温热年代学方法及其应用（一）\n",
      "http://www.hddz.cgsnjzx.cn/article/doi/10.16788/j.hddz.32-1865/P.2024.12.007\n",
      "============================================================================\n",
      "# 34 ---- 《海洋地质前沿》 -----------------------------------\n",
      "# 35 ---- 《华北地质》 -------------------------------------\n",
      "# 36 ---- 《地质与资源》 -------------------------------------\n",
      "# 37 ---- 《中国地质调查》 -------------------------------------\n",
      "# 38 ---- 《新疆石油地质》 -------------------------------------\n",
      "# 39 ---- 《石油与天然气地质》 -------------------------------------\n",
      "# 40 ---- 《油气地质与采收率》 -------------------------------------\n",
      "# 41 ---- 《石油勘探与开发》 -------------------------------------\n",
      "# 42 ---- 《华南地质》 ---------------------------------\n",
      "利用激光剥蚀（LA）-ICP-MS快速测定熔融玻璃片的稀土元素含量的方法以及华南木子店岩石样品的应用实例\n",
      "http://hndz.whcgs.cn/ch/reader/view_abstract.aspx?file_no=202502020&flag=1\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "print('# 31 ---- 《石油实验地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.sysydz.net/\")\n",
    "url =\"https://www.sysydz.net\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"info article-list-latest\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 石油实验地质')\n",
    "print('# 32 ---- 《地球科学与环境学报》 ----------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://jese.chd.edu.cn/\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"title\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地球科学与环境学报')\n",
    "print('# 33 ---- 《华东地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://www.hddz.cgsnjzx.cn/\")\n",
    "url =\"http://www.hddz.cgsnjzx.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 华东地质')\n",
    "print('# 34 ---- 《海洋地质前沿》 -----------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"http://www.jhyqy.com.cn/\")\n",
    "#print(driver.title)\n",
    "#using class name to select the tags (title and abstract) for searching\n",
    "tags = driver.find_elements(By.CLASS_NAME, \"article-list-title > a\")\n",
    "for tag in tags:\n",
    "    tag_ok=False\n",
    "    for i in range(len(keywords)):\n",
    "        if keywords[i] in tag.text:\n",
    "            tag_ok=True\n",
    "    if tag_ok:\n",
    "        print(tag.text)\n",
    "        link = tag.get_attribute(\"href\")\n",
    "        print(link)\n",
    "        print('=============================================================================')\n",
    "driver.quit()\n",
    "print('# 35 ---- 《华北地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://hbdz.org.cn/CN/home\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"j-title-1\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 华北地质')\n",
    "print('# 36 ---- 《地质与资源》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://www.dzyzy.cn/\")\n",
    "url =\"http://www.dzyzy.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-list-title clearfix\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(url+tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 地质与资源')\n",
    "print('# 37 ---- 《中国地质调查》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://journal25.magtechjournal.com/Jwk_dzdc/CN/volumn/home.shtml\")\n",
    "url=\"http://journal25.magtechjournal.com/Jwk_dzdc/CN\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "# def has_b(tag):\n",
    "#     return tag.b is not None\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('td', colspan=\"2\", height=\"22\", valign=\"center\"): \n",
    "        tag_ok=False\n",
    "        if tag.b !=None:\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in tag.b.text: \n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(tag.b.text.rstrip('*'))\n",
    "                address=tag.find_next('a', target='_blank')\n",
    "                print(url+address['href'].lstrip('.'))\n",
    "                print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 中国地质调查')\n",
    "print('# 38 ---- 《新疆石油地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.zgxjpg.com/CN/1001-3873/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 新疆石油地质')\n",
    "print('# 39 ---- 《石油与天然气地质》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://ogg.pepris.com/CN/0253-9985/home.shtml\")\n",
    "url =\"http://www.dzyzy.cn\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"noselectrow\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 石油与天然气地质')\n",
    "print('# 40 ---- 《油气地质与采收率》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"http://yqdzycsl.cnjournals.com/pgre/home\")\n",
    "url =\"http://yqdzycsl.cnjournals.com\"\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tags in soup.find_all('div',class_=\"des m-fl\"):\n",
    "        tag_title = tags.find('div',class_=\"title\")\n",
    "        tag_ref=tags.find('a',class_=\"pt1\")\n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag_title.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag_title.text)\n",
    "            print(urljoin(url,tag_ref['href']))\n",
    "else: \n",
    "    print('can not connet to 油气地质与采收率')\n",
    "print('# 41 ---- 《石油勘探与开发》 -------------------------------------')\n",
    "# using bs4 for static page\n",
    "response = requests.get(\"https://www.cpedm.com/CN/1000-0747/home.shtml\")\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup.find_all('div',class_=\"article-l article-w\"): \n",
    "        tag_ok=False\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in tag.a.text: \n",
    "                tag_ok=True\n",
    "        if tag_ok:\n",
    "            print(tag.a.text.strip())\n",
    "            print(tag.a['href']) # get the link for the article\n",
    "            print('============================================================================')\n",
    "else: \n",
    "    print('can not connet to 石油勘探与开发')\n",
    "\n",
    "print('# 42 ---- 《华南地质》 ---------------------------------')\n",
    "# Using selenium to get the dynamic page \n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.set_page_load_timeout(20)\n",
    "try:\n",
    "    driver.get(\"http://hndz.whcgs.cn/ch/index.aspx\")\n",
    "    # because the webpage is en in default and can only be changed to zh-CN by click \n",
    "    driver.find_element(By.LINK_TEXT, '显示全部').click()\n",
    "    time.sleep(3)\n",
    "    #using class name to select the tags (title and abstract) for searching\n",
    "    tags = driver.find_elements(By.CLASS_NAME, \"dqml\")\n",
    "    for tag in tags:\n",
    "        title = tag.find_element(By.TAG_NAME, 'a')\n",
    "        if title.text != None:\n",
    "            tag_ok=False\n",
    "            for i in range(len(keywords)):\n",
    "                if keywords[i] in title.text:\n",
    "                    tag_ok=True\n",
    "            if tag_ok:\n",
    "                print(title.text)\n",
    "                print(title.get_attribute(\"href\"))\n",
    "                print('=============================================================================')\n",
    "except TimeoutException:\n",
    "    print(\"连接超时！换个时间再试试！\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1dd19-5754-4647-99ff-172e77e3ad23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92762041-655a-4885-97f3-eb9830319fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3559e-7544-4e56-a453-1cb7ee128726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-database] *",
   "language": "python",
   "name": "conda-env-.conda-database-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
